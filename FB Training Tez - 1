{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1645683459027,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCKXVUpojDkD0Qb-JKIFieuoaxGhayWRIW_RNLKg=s64","userId":"15122983906308089605"},"user_tz":-330},"id":"pp526sNP8J9n","outputId":"afad39eb-8744-4437-e70b-37fe8d797472"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Feb 24 06:17:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tNuLJypy0FY"},"outputs":[],"source":["# ! gdown --id 1i2x7osfloYkXDHMRn0WuVs2P3m751cj1\n","# ! pip -q uninstall -y kaggle\n","# ! pip -q install --upgrade pip\n","# ! pip -q install kaggle --upgrade\n","# ! mkdir ~/.kaggle\n","# ! cp kaggle.json ~/.kaggle/\n","# ! chmod 600 ~/.kaggle/kaggle.json\n","# ! kaggle competitions download feedback-prize-2021\n","# ! kaggle datasets download aishikai/fb-corrected-train\n","# ! kaggle datasets download abhishek/fblongformerlarge1536"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3fCTILJ8Lgs"},"outputs":[],"source":["# ! unzip -q /content/feedback-prize-2021.zip -d data\n","# ! rm /content/feedback-prize-2021.zip\n","# ! unzip -q /content/fb-corrected-train.zip -d data\n","# ! rm /content/fb-corrected-train.zip\n","# ! unzip -q /content/fblongformerlarge1536.zip -d weights\n","# ! rm /content/fblongformerlarge1536.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NR2yK1ay94mJ"},"outputs":[],"source":["# !pip install -qq sentencepiece\n","# !pip install -qq transformers\n","# !pip install -qq tez\n","# !pip install -qq iterative-stratification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LwYy7LwB9RZn"},"outputs":[],"source":["# general\n","import pandas as pd\n","import numpy as np\n","import os\n","import copy\n","import random\n","from joblib import Parallel, delayed\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn import metrics\n","from sklearn.model_selection import KFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","import gc\n","from collections import defaultdict\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","# nlp\n","from sklearn.feature_extraction.text import CountVectorizer\n","import torch\n","import torch.nn as nn\n","from transformers import LongformerConfig, LongformerModel, LongformerTokenizerFast, AutoConfig, AutoModel, AutoTokenizer, AdamW, get_cosine_schedule_with_warmup\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","# tez\n","import tez\n","from tez import enums\n","from tez.callbacks import Callback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfWSOxa3-6CY"},"outputs":[],"source":["class Config:\n","    n_folds = 5\n","    num_workers = 12\n","    fold = 0\n","    model = \"allenai/longformer-large-4096\"\n","    lr = 1e-5\n","    output = \"/content/model\"\n","    input = \"/content/data\"\n","    max_len = 1536\n","    batch_size = 4\n","    valid_batch_size = 4\n","    epochs = 5\n","    accumulation_steps = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pw608GSf8r61"},"outputs":[],"source":["target_id_map = {\n","    \"B-Lead\": 0,\n","    \"I-Lead\": 1,\n","    \"B-Position\": 2,\n","    \"I-Position\": 3,\n","    \"B-Evidence\": 4,\n","    \"I-Evidence\": 5,\n","    \"B-Claim\": 6,\n","    \"I-Claim\": 7,\n","    \"B-Concluding Statement\": 8,\n","    \"I-Concluding Statement\": 9,\n","    \"B-Counterclaim\": 10,\n","    \"I-Counterclaim\": 11,\n","    \"B-Rebuttal\": 12,\n","    \"I-Rebuttal\": 13,\n","    \"O\": 14,\n","    \"PAD\": -100,\n","}\n","\n","\n","id_target_map = {v: k for k, v in target_id_map.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSRC0VLiAWjS"},"outputs":[],"source":["def create_folds(df):\n","    dfx = pd.get_dummies(df, columns=[\"discourse_type\"]).groupby([\"id\"], as_index=False).sum()\n","    cols = [c for c in dfx.columns if c.startswith(\"discourse_type_\") or c == \"id\" and c != \"discourse_type_num\"]\n","    dfx = dfx[cols]\n","\n","    mskf = MultilabelStratifiedKFold(n_splits=Config.n_folds, shuffle=True, random_state=42)\n","    labels = [c for c in dfx.columns if c != \"id\"]\n","    dfx_labels = dfx[labels]\n","    dfx[\"kfold\"] = -1\n","\n","    for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","        print(len(trn_), len(val_))\n","        dfx.loc[val_, \"kfold\"] = fold\n","\n","    df = df.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\n","    print(df.kfold.value_counts())\n","    df.to_csv(\"train_folds.csv\", index=False)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZmcGDbo8wbA"},"outputs":[],"source":["def _prepare_training_data_helper(Config, tokenizer, df, train_ids):\n","    training_samples = []\n","    for idx in tqdm(train_ids):\n","        filename = os.path.join(Config.input, \"train\", idx + \".txt\")\n","        with open(filename, \"r\") as f:\n","            text = f.read()\n","\n","        encoded_text = tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=False,\n","            return_offsets_mapping=True,\n","        )\n","        input_ids = encoded_text[\"input_ids\"]\n","        input_labels = copy.deepcopy(input_ids)\n","        offset_mapping = encoded_text[\"offset_mapping\"]\n","\n","        for k in range(len(input_labels)):\n","            input_labels[k] = \"O\"\n","\n","        sample = {\n","            \"id\": idx,\n","            \"input_ids\": input_ids,\n","            \"text\": text,\n","            \"offset_mapping\": offset_mapping,\n","        }\n","\n","        temp_df = df[df[\"id\"] == idx]\n","        for _, row in temp_df.iterrows():\n","            text_labels = [0] * len(text)\n","            discourse_start = int(row[\"discourse_start\"])\n","            discourse_end = int(row[\"discourse_end\"])\n","            prediction_label = row[\"discourse_type\"]\n","            text_labels[discourse_start:discourse_end] = [1] * (discourse_end - discourse_start)\n","            target_idx = []\n","            for map_idx, (offset1, offset2) in enumerate(encoded_text[\"offset_mapping\"]):\n","                if sum(text_labels[offset1:offset2]) > 0:\n","                    if len(text[offset1:offset2].split()) > 0:\n","                        target_idx.append(map_idx)\n","\n","            targets_start = target_idx[0]\n","            targets_end = target_idx[-1]\n","            pred_start = \"B-\" + prediction_label\n","            pred_end = \"I-\" + prediction_label\n","            input_labels[targets_start] = pred_start\n","            input_labels[targets_start + 1 : targets_end + 1] = [pred_end] * (targets_end - targets_start)\n","\n","        sample[\"input_ids\"] = input_ids\n","        sample[\"input_labels\"] = input_labels\n","        training_samples.append(sample)\n","    return training_samples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCAHgI7E82Or"},"outputs":[],"source":["## Metric Utils\n","def calc_overlap(row):\n","    \"\"\"\n","    Calculates the overlap between prediction and\n","    ground truth and overlap percentages used for determining\n","    true positives.\n","    \"\"\"\n","    set_pred = set(row.predictionstring_pred.split(\" \"))\n","    set_gt = set(row.predictionstring_gt.split(\" \"))\n","    # Length of each and intersection\n","    len_gt = len(set_gt)\n","    len_pred = len(set_pred)\n","    inter = len(set_gt.intersection(set_pred))\n","    overlap_1 = inter / len_gt\n","    overlap_2 = inter / len_pred\n","    return [overlap_1, overlap_2]\n","\n","\n","def score_feedback_comp_micro(pred_df, gt_df):\n","    \"\"\"\n","    A function that scores for the kaggle\n","        Student Writing Competition\n","    Uses the steps in the evaluation page here:\n","        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n","    This code is from Rob Mulla's Kaggle kernel.\n","    \"\"\"\n","    gt_df = gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True).copy()\n","    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n","    pred_df[\"pred_id\"] = pred_df.index\n","    gt_df[\"gt_id\"] = gt_df.index\n","    # Step 1. all ground truths and predictions for a given class are compared.\n","    joined = pred_df.merge(\n","        gt_df,\n","        left_on=[\"id\", \"class\"],\n","        right_on=[\"id\", \"discourse_type\"],\n","        how=\"outer\",\n","        suffixes=(\"_pred\", \"_gt\"),\n","    )\n","    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n","    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n","\n","    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n","\n","    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n","    # and the overlap between the prediction and the ground truth >= 0.5,\n","    # the prediction is a match and considered a true positive.\n","    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n","    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n","    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n","\n","    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n","    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n","    tp_pred_ids = (\n","        joined.query(\"potential_TP\")\n","        .sort_values(\"max_overlap\", ascending=False)\n","        .groupby([\"id\", \"predictionstring_gt\"])\n","        .first()[\"pred_id\"]\n","        .values\n","    )\n","\n","    # 3. Any unmatched ground truths are false negatives\n","    # and any unmatched predictions are false positives.\n","    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n","\n","    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n","    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n","\n","    # Get numbers of each type\n","    TP = len(tp_pred_ids)\n","    FP = len(fp_pred_ids)\n","    FN = len(unmatched_gt_ids)\n","    # calc microf1\n","    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n","    return my_f1_score\n","\n","\n","def score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n","    class_scores = {}\n","    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n","    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n","        pred_subset = pred_df.loc[pred_df[\"class\"] == discourse_type].reset_index(drop=True).copy()\n","        class_score = score_feedback_comp_micro(pred_subset, gt_subset)\n","        class_scores[discourse_type] = class_score\n","    f1 = np.mean([v for v in class_scores.values()])\n","    if return_class_scores:\n","        return f1, class_scores\n","    return f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lmvxe7gZ8xBF"},"outputs":[],"source":["def prepare_training_data(df, tokenizer, Config, num_jobs):\n","    training_samples = []\n","    train_ids = df[\"id\"].unique()\n","\n","    train_ids_splits = np.array_split(train_ids, num_jobs)\n","\n","    results = Parallel(n_jobs=num_jobs, backend=\"multiprocessing\")(\n","        delayed(_prepare_training_data_helper)(Config, tokenizer, df, idx) for idx in train_ids_splits\n","    )\n","    for result in results:\n","        training_samples.extend(result)\n","\n","    return training_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rv9VcjQF8QFc"},"outputs":[],"source":["class FeedbackDataset:\n","    def __init__(self, samples, max_len, tokenizer):\n","        self.samples = samples\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.length = len(samples)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.samples[idx][\"input_ids\"]\n","        input_labels = self.samples[idx][\"input_labels\"]\n","        input_labels = [target_id_map[x] for x in input_labels]\n","        other_label_id = target_id_map[\"O\"]\n","        padding_label_id = target_id_map[\"PAD\"]\n","        # print(input_ids)\n","        # print(input_labels)\n","\n","        # add start token id to the input_ids\n","        input_ids = [self.tokenizer.cls_token_id] + input_ids\n","        input_labels = [other_label_id] + input_labels\n","\n","        if len(input_ids) > self.max_len - 1:\n","            input_ids = input_ids[: self.max_len - 1]\n","            input_labels = input_labels[: self.max_len - 1]\n","\n","        # add end token id to the input_ids\n","        input_ids = input_ids + [self.tokenizer.sep_token_id]\n","        input_labels = input_labels + [other_label_id]\n","\n","        attention_mask = [1] * len(input_ids)\n","\n","        padding_length = self.max_len - len(input_ids)\n","        if padding_length > 0:\n","            if self.tokenizer.padding_side == \"right\":\n","                input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n","                input_labels = input_labels + [padding_label_id] * padding_length\n","                attention_mask = attention_mask + [0] * padding_length\n","            else:\n","                input_ids = [self.tokenizer.pad_token_id] * padding_length + input_ids\n","                input_labels = [padding_label_id] * padding_length + input_labels\n","                attention_mask = [0] * padding_length + attention_mask\n","\n","        return {\n","            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n","            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n","            \"targets\": torch.tensor(input_labels, dtype=torch.long),\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00p-H50V875X"},"outputs":[],"source":["class FeedbackDatasetValid:\n","    def __init__(self, samples, max_len, tokenizer):\n","        self.samples = samples\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.length = len(samples)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.samples[idx][\"input_ids\"]\n","        input_ids = [self.tokenizer.cls_token_id] + input_ids\n","\n","        if len(input_ids) > self.max_len - 1:\n","            input_ids = input_ids[: self.max_len - 1]\n","\n","        # add end token id to the input_ids\n","        input_ids = input_ids + [self.tokenizer.sep_token_id]\n","        attention_mask = [1] * len(input_ids)\n","\n","        return {\n","            \"ids\": input_ids,\n","            \"mask\": attention_mask,\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBVXrTL389GN"},"outputs":[],"source":["class Collate:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n","        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n","            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n","        else:\n","            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n","            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n","\n","        # convert to tensors\n","        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n","        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81deEQ398ZeG"},"outputs":[],"source":["class FeedbackModel(tez.Model):\n","    def __init__(self, model_name, num_train_steps, learning_rate, num_labels, steps_per_epoch):\n","        super().__init__()\n","        self.learning_rate = learning_rate\n","        self.model_name = model_name\n","        self.num_train_steps = num_train_steps\n","        self.num_labels = num_labels\n","        self.steps_per_epoch = steps_per_epoch\n","        self.step_scheduler_after = \"batch\"\n","\n","        hidden_dropout_prob: float = 0.1\n","        layer_norm_eps: float = 1e-7\n","\n","        config = AutoConfig.from_pretrained(model_name)\n","\n","        config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": hidden_dropout_prob,\n","                \"layer_norm_eps\": layer_norm_eps,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": self.num_labels,\n","            }\n","        )\n","        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        self.output = nn.Linear(config.hidden_size, self.num_labels)\n","\n","    def fetch_optimizer(self):\n","        param_optimizer = list(self.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\"]\n","        optimizer_parameters = [\n","            {\n","                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.01,\n","            },\n","            {\n","                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        opt = AdamW(optimizer_parameters, lr=self.learning_rate)\n","        return opt\n","\n","    def fetch_scheduler(self):\n","        sch = get_cosine_schedule_with_warmup(\n","            self.optimizer,\n","            num_warmup_steps=int(0.1 * self.num_train_steps),\n","            num_training_steps=self.num_train_steps,\n","            num_cycles=1,\n","            last_epoch=-1,\n","        )\n","        return sch\n","\n","    def loss(self, outputs, targets, attention_mask):\n","        loss_fct = nn.CrossEntropyLoss()\n","\n","        active_loss = attention_mask.view(-1) == 1\n","        active_logits = outputs.view(-1, self.num_labels)\n","        true_labels = targets.view(-1)\n","        outputs = active_logits.argmax(dim=-1)\n","        idxs = np.where(active_loss.cpu().numpy() == 1)[0]\n","        active_logits = active_logits[idxs]\n","        true_labels = true_labels[idxs].to(torch.long)\n","\n","        loss = loss_fct(active_logits, true_labels)\n","        return loss\n","\n","    def monitor_metrics(self, outputs, targets, attention_mask):\n","        active_loss = (attention_mask.view(-1) == 1).cpu().numpy()\n","        active_logits = outputs.view(-1, self.num_labels)\n","        true_labels = targets.view(-1).cpu().numpy()\n","        outputs = active_logits.argmax(dim=-1).cpu().numpy()\n","        idxs = np.where(active_loss == 1)[0]\n","        f1_score = metrics.f1_score(true_labels[idxs], outputs[idxs], average=\"macro\")\n","        return {\"f1\": f1_score}\n","\n","    def forward(self, ids, mask, token_type_ids=None, targets=None):\n","\n","        if token_type_ids:\n","            transformer_out = self.transformer(ids, mask, token_type_ids)\n","        else:\n","            transformer_out = self.transformer(ids, mask)\n","        sequence_output = transformer_out.last_hidden_state\n","        sequence_output = self.dropout(sequence_output)\n","\n","        logits1 = self.output(self.dropout1(sequence_output))\n","        logits2 = self.output(self.dropout2(sequence_output))\n","        logits3 = self.output(self.dropout3(sequence_output))\n","        logits4 = self.output(self.dropout4(sequence_output))\n","        logits5 = self.output(self.dropout5(sequence_output))\n","\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        logits = torch.softmax(logits, dim=-1)\n","        loss = 0\n","\n","        if targets is not None:\n","            loss1 = self.loss(logits1, targets, attention_mask=mask)\n","            loss2 = self.loss(logits2, targets, attention_mask=mask)\n","            loss3 = self.loss(logits3, targets, attention_mask=mask)\n","            loss4 = self.loss(logits4, targets, attention_mask=mask)\n","            loss5 = self.loss(logits5, targets, attention_mask=mask)\n","            loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5\n","            f1_1 = self.monitor_metrics(logits1, targets, attention_mask=mask)[\"f1\"]\n","            f1_2 = self.monitor_metrics(logits2, targets, attention_mask=mask)[\"f1\"]\n","            f1_3 = self.monitor_metrics(logits3, targets, attention_mask=mask)[\"f1\"]\n","            f1_4 = self.monitor_metrics(logits4, targets, attention_mask=mask)[\"f1\"]\n","            f1_5 = self.monitor_metrics(logits5, targets, attention_mask=mask)[\"f1\"]\n","            f1 = (f1_1 + f1_2 + f1_3 + f1_4 + f1_5) / 5\n","            metric = {\"f1\": f1}\n","            return logits, loss, metric\n","\n","        return logits, loss, {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdxlawty9JG0"},"outputs":[],"source":["class EarlyStopping(Callback):\n","    def __init__(\n","        self,\n","        model_path,\n","        valid_df,\n","        valid_samples,\n","        batch_size,\n","        tokenizer,\n","        patience=5,\n","        mode=\"max\",\n","        delta=0.001,\n","        save_weights_only=True,\n","    ):\n","        self.patience = patience\n","        self.counter = 0\n","        self.mode = mode\n","        self.best_score = None\n","        self.early_stop = False\n","        self.delta = delta\n","        self.save_weights_only = save_weights_only\n","        self.model_path = model_path\n","        self.valid_samples = valid_samples\n","        self.batch_size = batch_size\n","        self.valid_df = valid_df\n","        self.tokenizer = tokenizer\n","\n","        if self.mode == \"min\":\n","            self.val_score = np.Inf\n","        else:\n","            self.val_score = -np.Inf\n","\n","    def on_epoch_end(self, model):\n","        model.eval()\n","        valid_dataset = FeedbackDatasetValid(self.valid_samples, 4096, self.tokenizer)\n","        collate = Collate(self.tokenizer)\n","\n","        preds_iter = model.predict(\n","            valid_dataset,\n","            batch_size=self.batch_size,\n","            n_jobs=-1,\n","            collate_fn=collate,\n","        )\n","\n","        final_preds = []\n","        final_scores = []\n","        for preds in preds_iter:\n","            pred_class = np.argmax(preds, axis=2)\n","            pred_scrs = np.max(preds, axis=2)\n","            for pred, pred_scr in zip(pred_class, pred_scrs):\n","                final_preds.append(pred.tolist())\n","                final_scores.append(pred_scr.tolist())\n","\n","        for j in range(len(self.valid_samples)):\n","            tt = [id_target_map[p] for p in final_preds[j][1:]]\n","            tt_score = final_scores[j][1:]\n","            self.valid_samples[j][\"preds\"] = tt\n","            self.valid_samples[j][\"pred_scores\"] = tt_score\n","\n","        submission = []\n","        min_thresh = {\n","            \"Lead\": 9,\n","            \"Position\": 5,\n","            \"Evidence\": 14,\n","            \"Claim\": 3,\n","            \"Concluding Statement\": 11,\n","            \"Counterclaim\": 6,\n","            \"Rebuttal\": 4,\n","        }\n","        proba_thresh = {\n","            \"Lead\": 0.7,\n","            \"Position\": 0.55,\n","            \"Evidence\": 0.65,\n","            \"Claim\": 0.55,\n","            \"Concluding Statement\": 0.7,\n","            \"Counterclaim\": 0.5,\n","            \"Rebuttal\": 0.55,\n","        }\n","\n","        for _, sample in enumerate(self.valid_samples):\n","            preds = sample[\"preds\"]\n","            offset_mapping = sample[\"offset_mapping\"]\n","            sample_id = sample[\"id\"]\n","            sample_text = sample[\"text\"]\n","            sample_pred_scores = sample[\"pred_scores\"]\n","\n","            # pad preds to same length as offset_mapping\n","            if len(preds) < len(offset_mapping):\n","                preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n","                sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n","\n","            idx = 0\n","            phrase_preds = []\n","            while idx < len(offset_mapping):\n","                start, _ = offset_mapping[idx]\n","                if preds[idx] != \"O\":\n","                    label = preds[idx][2:]\n","                else:\n","                    label = \"O\"\n","                phrase_scores = []\n","                phrase_scores.append(sample_pred_scores[idx])\n","                idx += 1\n","                while idx < len(offset_mapping):\n","                    if label == \"O\":\n","                        matching_label = \"O\"\n","                    else:\n","                        matching_label = f\"I-{label}\"\n","                    if preds[idx] == matching_label:\n","                        _, end = offset_mapping[idx]\n","                        phrase_scores.append(sample_pred_scores[idx])\n","                        idx += 1\n","                    else:\n","                        break\n","                if \"end\" in locals():\n","                    phrase = sample_text[start:end]\n","                    phrase_preds.append((phrase, start, end, label, phrase_scores))\n","\n","            temp_df = []\n","            for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n","                word_start = len(sample_text[:start].split())\n","                word_end = word_start + len(sample_text[start:end].split())\n","                word_end = min(word_end, len(sample_text.split()))\n","                ps = \" \".join([str(x) for x in range(word_start, word_end)])\n","                if label != \"O\":\n","                    if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n","                        temp_df.append((sample_id, label, ps))\n","\n","            temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n","\n","            submission.append(temp_df)\n","\n","        submission = pd.concat(submission).reset_index(drop=True)\n","        submission[\"len\"] = submission.predictionstring.apply(lambda x: len(x.split()))\n","\n","        def threshold(df):\n","            df = df.copy()\n","            for key, value in min_thresh.items():\n","                index = df.loc[df[\"class\"] == key].query(f\"len<{value}\").index\n","                df.drop(index, inplace=True)\n","            return df\n","\n","        submission = threshold(submission)\n","\n","        # drop len\n","        submission = submission.drop(columns=[\"len\"])\n","\n","        scr = score_feedback_comp(submission, self.valid_df, return_class_scores=True)\n","        print(scr)\n","        model.train()\n","\n","        epoch_score = scr[0]\n","        if self.mode == \"min\":\n","            score = -1.0 * epoch_score\n","        else:\n","            score = np.copy(epoch_score)\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(epoch_score, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n","            if self.counter >= self.patience:\n","                model.model_state = enums.ModelState.END\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(epoch_score, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, epoch_score, model):\n","        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n","            print(\"Validation score improved ({} --> {}). Saving model!\".format(self.val_score, epoch_score))\n","            model.save(self.model_path, weights_only=self.save_weights_only)\n","        self.val_score = epoch_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":766},"id":"2RlYA_qz8hrp","outputId":"3a284515-424e-48c9-eca4-de1c5e27a5ef","executionInfo":{"status":"ok","timestamp":1645538138298,"user_tz":-330,"elapsed":13048202,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCKXVUpojDkD0Qb-JKIFieuoaxGhayWRIW_RNLKg=s64","userId":"15122983906308089605"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["12477 3117\n","12474 3120\n","12475 3119\n","12475 3119\n","12475 3119\n","0    28997\n","2    28968\n","3    28904\n","1    28737\n","4    28687\n","Name: kfold, dtype: int64\n","Training Fold 0\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (8862 > 4096). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (6229 > 4096). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (7614 > 4096). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (8580 > 4096). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (14778 > 4096). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (4105 > 4096). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["15596\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/longformer-large-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 3120/3120 [41:22<00:00,  1.26it/s, f1=0.717, loss=0.428, stage=train]\n","100%|██████████| 780/780 [01:41<00:00,  7.68it/s, stage=test]\n"]},{"output_type":"stream","name":"stdout","text":["(0.6282559770040338, {'Claim': 0.6133503265891349, 'Concluding Statement': 0.7424982554082344, 'Counterclaim': 0.4847457627118644, 'Evidence': 0.7520885075637842, 'Lead': 0.7624678663239075, 'Position': 0.6745812327207676, 'Rebuttal': 0.3680598877105427})\n","Validation score improved (-inf --> 0.6282559770040338). Saving model!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3120/3120 [41:24<00:00,  1.26it/s, f1=0.75, loss=0.371, stage=train]\n","100%|██████████| 780/780 [01:41<00:00,  7.69it/s, stage=test]\n"]},{"output_type":"stream","name":"stdout","text":["(0.6521883860118541, {'Claim': 0.6251848721740968, 'Concluding Statement': 0.8285191956124315, 'Counterclaim': 0.5058264997842037, 'Evidence': 0.7402783915156872, 'Lead': 0.7678051363516017, 'Position': 0.6919871794871795, 'Rebuttal': 0.405717427157779})\n","Validation score improved (0.6282559770040338 --> 0.6521883860118541). Saving model!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3120/3120 [41:24<00:00,  1.26it/s, f1=0.795, loss=0.289, stage=train]\n","100%|██████████| 780/780 [01:41<00:00,  7.69it/s, stage=test]\n"]},{"output_type":"stream","name":"stdout","text":["(0.6477446498602782, {'Claim': 0.6234777400678778, 'Concluding Statement': 0.8300180831826401, 'Counterclaim': 0.5036855036855037, 'Evidence': 0.7281664755038506, 'Lead': 0.7588726513569938, 'Position': 0.684286865431104, 'Rebuttal': 0.40570522979397783})\n","EarlyStopping counter: 1 out of 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3120/3120 [41:24<00:00,  1.26it/s, f1=0.797, loss=0.286, stage=train]\n","100%|██████████| 780/780 [01:41<00:00,  7.68it/s, stage=test]\n"]},{"output_type":"stream","name":"stdout","text":["(0.6453460535352934, {'Claim': 0.6201997118585126, 'Concluding Statement': 0.8234214390602056, 'Counterclaim': 0.4888304862023653, 'Evidence': 0.7318836610615107, 'Lead': 0.786815523657629, 'Position': 0.6772908366533864, 'Rebuttal': 0.38898071625344355})\n","EarlyStopping counter: 2 out of 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3120/3120 [41:25<00:00,  1.26it/s, f1=0.785, loss=0.308, stage=train]\n","100%|██████████| 780/780 [01:41<00:00,  7.68it/s, stage=test]\n"]},{"output_type":"stream","name":"stdout","text":["(0.6420102005465688, {'Claim': 0.6280967788670498, 'Concluding Statement': 0.8022134951802927, 'Counterclaim': 0.4892205638474295, 'Evidence': 0.7397365112338052, 'Lead': 0.795869737887212, 'Position': 0.668066548215151, 'Rebuttal': 0.37086776859504134})\n","EarlyStopping counter: 3 out of 5\n"]}],"source":["df = pd.read_csv(os.path.join(Config.input, \"corrected_train.csv\"))\n","df = create_folds(df)\n","\n","os.makedirs(\"model\", exist_ok = True)\n","\n","for fold in range(1):\n","\n","    print(f\"Training Fold {fold}\")\n","    train_df = df[df[\"kfold\"] != fold].reset_index(drop=True)\n","    valid_df = df[df[\"kfold\"] == fold].reset_index(drop=True)\n","\n","    tokenizer = AutoTokenizer.from_pretrained(Config.model)\n","    training_samples = prepare_training_data(train_df, tokenizer, Config, num_jobs=Config.num_workers)\n","    valid_samples = prepare_training_data(valid_df, tokenizer, Config, num_jobs=Config.num_workers)\n","\n","    train_dataset = FeedbackDataset(training_samples, Config.max_len, tokenizer)\n","\n","    num_train_steps = int(len(train_dataset) / Config.batch_size / Config.accumulation_steps * Config.epochs)\n","    print(num_train_steps)\n","\n","    model = FeedbackModel(\n","        model_name=Config.model,\n","        num_train_steps=num_train_steps,\n","        learning_rate=Config.lr,\n","        num_labels=len(target_id_map) - 1,\n","        steps_per_epoch=len(train_dataset) / Config.batch_size,\n","    )\n","\n","    model.load(f\"/content/weights/model_{fold}.bin\", weights_only = True)\n","\n","    es = EarlyStopping(\n","        model_path=os.path.join(Config.output, f\"model_{fold}.bin\"),\n","        valid_df=valid_df,\n","        valid_samples=valid_samples,\n","        batch_size=Config.valid_batch_size,\n","        patience=5,\n","        mode=\"max\",\n","        delta=0.001,\n","        save_weights_only=True,\n","        tokenizer=tokenizer,\n","    )\n","\n","    model.fit(\n","        train_dataset,\n","        train_bs=Config.batch_size,\n","        device=\"cuda\",\n","        epochs=Config.epochs,\n","        callbacks=[es],\n","        fp16=True,\n","        accumulation_steps=Config.accumulation_steps,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FOXNSuyAwzU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645538970380,"user_tz":-330,"elapsed":831586,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCKXVUpojDkD0Qb-JKIFieuoaxGhayWRIW_RNLKg=s64","userId":"15122983906308089605"}},"outputId":"9994eeb9-e00c-4d22-957a-4e138267e379"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: model/ (stored 0%)\n","  adding: model/model_0.bin (deflated 14%)\n","  adding: model/model_4.bin (deflated 14%)\n","  adding: model/model_3.bin (deflated 14%)\n","  adding: model/model_2.bin (deflated 14%)\n","  adding: model/model_1.bin (deflated 14%)\n"]}],"source":["save_file = \"/content/drive/MyDrive/longformer-large-AT-FB-tez.zip\"\n","! zip -r $save_file model"]},{"cell_type":"code","source":[""],"metadata":{"id":"2GFABNbatwCr"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"FB Training Tez - 1","provenance":[],"mount_file_id":"1vjIsWAPpLhGRiE2zGDboR5OYOX3TAvb4","authorship_tag":"ABX9TyOgmjpTYMrRgTIf2bcVQQ6B"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}