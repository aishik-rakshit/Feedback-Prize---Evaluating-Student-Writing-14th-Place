{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":576,"status":"ok","timestamp":1647327710677,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"},"user_tz":-330},"id":"OVVpCpgah-h9","outputId":"a2669ad0-7eb8-4e0a-d8cc-2dc11beba43d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Mar 15 07:01:49 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P0    53W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"o1BUykIdh92h","executionInfo":{"status":"ok","timestamp":1647327710677,"user_tz":-330,"elapsed":12,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["# ! gdown --id 1i2x7osfloYkXDHMRn0WuVs2P3m751cj1\n","# ! pip -q uninstall -y kaggle\n","# ! pip -q install --upgrade pip\n","# ! pip -q install kaggle --upgrade\n","# ! mkdir ~/.kaggle\n","# ! cp kaggle.json ~/.kaggle/\n","# ! chmod 600 ~/.kaggle/kaggle.json\n","# ! kaggle competitions download feedback-prize-2021\n","# ! kaggle datasets download aishikai/fb-corrected-train\n","# ! kaggle datasets download aishikai/fb-deberta-2"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Ugm9V5RNiBoV","executionInfo":{"status":"ok","timestamp":1647327710678,"user_tz":-330,"elapsed":13,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["# ! unzip -q /content/feedback-prize-2021.zip -d data\n","# ! rm /content/feedback-prize-2021.zip\n","# ! unzip -q /content/fb-corrected-train.zip -d data\n","# ! rm /content/fb-corrected-train.zip\n","# ! unzip -q /content/fb-deberta-2.zip\n","# ! rm /content/fb-deberta-2.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3AgzNtu_iDQX","executionInfo":{"status":"ok","timestamp":1647327710678,"user_tz":-330,"elapsed":12,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["# !pip install -qq sentencepiece\n","# !pip install -qq transformers\n","# !pip install -qq iterative-stratification\n","# !pip install -qq scikit-optimize"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MpNB96I2htH9","executionInfo":{"status":"ok","timestamp":1647327714840,"user_tz":-330,"elapsed":4173,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["# general\n","import pandas as pd\n","import numpy as np\n","import os\n","import copy\n","import pickle\n","import random\n","from joblib import Parallel, delayed\n","from multiprocessing import Manager\n","from tqdm.notebook import tqdm\n","from scipy import stats\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn import metrics\n","from sklearn.model_selection import KFold\n","from collections import Counter\n","from bisect import bisect_left\n","from sklearn.model_selection import cross_val_score, GroupKFold\n","from sklearn.ensemble import GradientBoostingClassifier\n","from skopt.space import Real\n","from skopt import gp_minimize\n","import sys\n","import xgboost\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","import gc\n","from collections import defaultdict\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","# nlp\n","from sklearn.feature_extraction.text import CountVectorizer\n","import torch\n","import torch.nn as nn\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_cosine_schedule_with_warmup\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2zzNxoYPh7RD","executionInfo":{"status":"ok","timestamp":1647327714841,"user_tz":-330,"elapsed":65,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["class Config:\n","    savename = \"deberta-xlarge\"\n","    n_folds = 5\n","    num_workers = 12\n","    fold = 0\n","    model = \"microsoft/deberta-xlarge\"\n","    lr = 2.5e-5\n","    n_accum = 1\n","    max_grad_norm = 10\n","    output = \"/content/model\"\n","    input = \"/content/data\"\n","    max_len = 1024\n","    max_len_valid = 1600\n","    num_labels = 15\n","    batch_size = 2\n","    valid_batch_size = 2\n","    epochs = 6\n","    accumulation_steps = 1\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    apex = True\n","    debug = False\n","    if debug:\n","        n_folds = 2\n","        epochs = 2"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"aS1G93V0iN1-","executionInfo":{"status":"ok","timestamp":1647327714842,"user_tz":-330,"elapsed":64,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def get_texts(path):\n","    names, texts = [], []\n","    for f in list(os.listdir(path)):\n","        names.append(f.replace('.txt', ''))\n","        texts.append(open(path + f, 'r').read())\n","    texts = pd.DataFrame({'id': names, 'text': texts})\n","    return texts"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"INpo-3nHt_p7","executionInfo":{"status":"ok","timestamp":1647327714843,"user_tz":-330,"elapsed":63,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def create_folds(df):\n","    dfx = pd.get_dummies(df, columns=[\"discourse_type\"]).groupby([\"id\"], as_index=False).sum()\n","    cols = [c for c in dfx.columns if c.startswith(\"discourse_type_\") or c == \"id\" and c != \"discourse_type_num\"]\n","    dfx = dfx[cols]\n","\n","    mskf = MultilabelStratifiedKFold(n_splits=Config.n_folds, shuffle=True, random_state=42)\n","    labels = [c for c in dfx.columns if c != \"id\"]\n","    dfx_labels = dfx[labels]\n","    dfx[\"kfold\"] = -1\n","\n","    for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","        print(len(trn_), len(val_))\n","        dfx.loc[val_, \"kfold\"] = fold\n","\n","    df = df.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\n","    print(df.kfold.value_counts())\n","    df.to_csv(\"train_folds.csv\", index=False)\n","    return df"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"oHOJXeKMlD9M","executionInfo":{"status":"ok","timestamp":1647327714843,"user_tz":-330,"elapsed":62,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def get_labels(text_df, train_df):\n","    all_entities = []\n","    for ii,i in tqdm(enumerate(text_df.iterrows()), total = len(text_df)):\n","        total = i[1]['text'].split().__len__()\n","        entities = [\"O\"]*total\n","        for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n","            discourse = j[1]['discourse_type']\n","            list_ix = [int(x) for x in j[1]['predictionstring'].split(' ')]\n","            entities[list_ix[0]] = f\"B-{discourse}\"\n","            for k in list_ix[1:]: entities[k] = f\"I-{discourse}\"\n","        all_entities.append(entities)\n","    text_df['entities'] = all_entities\n","    text_df.to_csv('train_NER.csv',index=False)\n","    return text_df"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"GWl7gwX7lvON","executionInfo":{"status":"ok","timestamp":1647327714844,"user_tz":-330,"elapsed":62,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n","          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n","\n","labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n","ids_to_labels = {k:v for k,v in enumerate(output_labels)}\n","disc_type_to_ids = {'Evidence':(11,12),'Claim':(5,6),'Lead':(1,2),'Position':(3,4),'Counterclaim':(7,8),'Rebuttal':(9,10),'Concluding Statement':(13,14)}"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"huq5TLkzlyu7","executionInfo":{"status":"ok","timestamp":1647327714845,"user_tz":-330,"elapsed":62,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def split_mapping(unsplit):\n","    splt = unsplit.split()\n","    offset_to_wordidx = np.full(len(unsplit),-1)\n","    txt_ptr = 0\n","    for split_index, full_word in enumerate(splt):\n","        while unsplit[txt_ptr:txt_ptr + len(full_word)] != full_word:\n","            txt_ptr += 1\n","        offset_to_wordidx[txt_ptr:txt_ptr + len(full_word)] = split_index\n","        txt_ptr += len(full_word)\n","    return offset_to_wordidx"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"pCNxWLTFnMil","executionInfo":{"status":"ok","timestamp":1647327714846,"user_tz":-330,"elapsed":62,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["class feedbackDataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len, get_wids):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.get_wids = get_wids # for validation\n","\n","  def __getitem__(self, index):\n","        # GET TEXT AND WORD LABELS \n","        text = self.data.text[index]        \n","        word_labels = self.data.entities[index] if not self.get_wids else None\n","\n","        # TOKENIZE TEXT\n","        encoding = self.tokenizer(text,\n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        word_ids = encoding.word_ids()  \n","        split_word_ids = np.full(len(word_ids),-1)\n","        offset_to_wordidx = split_mapping(text)\n","        offsets = encoding['offset_mapping']\n","        \n","        # CREATE TARGETS AND MAPPING OF TOKENS TO SPLIT() WORDS\n","        label_ids = []\n","        # Iterate in reverse to label whitespace tokens until a Begin token is encountered\n","        for token_idx, word_idx in reversed(list(enumerate(word_ids))):\n","            \n","            if word_idx is None:\n","                if not self.get_wids: label_ids.append(-100)\n","            else:\n","                if offsets[token_idx] != (0,0):\n","                    #Choose the split word that shares the most characters with the token if any\n","                    split_idxs = offset_to_wordidx[offsets[token_idx][0]:offsets[token_idx][1]]\n","                    split_index = stats.mode(split_idxs[split_idxs != -1]).mode[0] if len(np.unique(split_idxs)) > 1 else split_idxs[0]\n","                    \n","                    if split_index != -1: \n","                        if not self.get_wids: label_ids.append( labels_to_ids[word_labels[split_index]] )\n","                        split_word_ids[token_idx] = split_index\n","                    else:\n","                        # Even if we don't find a word, continue labeling 'I' tokens until a 'B' token is found\n","                        if label_ids and label_ids[-1] != -100 and ids_to_labels[label_ids[-1]][0] == 'I':\n","                            split_word_ids[token_idx] = split_word_ids[token_idx + 1]\n","                            if not self.get_wids: label_ids.append(label_ids[-1])\n","                        else:\n","                            if not self.get_wids: label_ids.append(-100)\n","                else:\n","                    if not self.get_wids: label_ids.append(-100)\n","        \n","        encoding['labels'] = list(reversed(label_ids))\n","\n","        # CONVERT TO TORCH TENSORS\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        if self.get_wids: \n","            item['wids'] = torch.as_tensor(split_word_ids)\n","        \n","        return item\n","\n","  def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"QLGdNtrBnRIX","executionInfo":{"status":"ok","timestamp":1647327714846,"user_tz":-330,"elapsed":61,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["class FeedbackModel(nn.Module):\n","    def __init__(self, model_name, num_labels):\n","        super().__init__()\n","        self.model_name = model_name\n","        self.num_labels = num_labels\n","\n","        hidden_dropout_prob: float = 0.1\n","        layer_norm_eps: float = 1e-7\n","\n","        config = AutoConfig.from_pretrained(Config.model)\n","\n","        config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": hidden_dropout_prob,\n","                \"layer_norm_eps\": layer_norm_eps,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": self.num_labels,\n","            }\n","        )\n","        self.transformer = AutoModel.from_pretrained(Config.model, config=config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        self.output = nn.Linear(config.hidden_size, self.num_labels)\n","\n","    def forward(self, ids, mask, token_type_ids=None):\n","\n","        if token_type_ids:\n","            transformer_out = self.transformer(ids, mask, token_type_ids)\n","        else:\n","            transformer_out = self.transformer(ids, mask)\n","        sequence_output = transformer_out.last_hidden_state\n","        sequence_output = self.dropout(sequence_output)\n","\n","        logits1 = self.output(self.dropout1(sequence_output))\n","        logits2 = self.output(self.dropout2(sequence_output))\n","        logits3 = self.output(self.dropout3(sequence_output))\n","        logits4 = self.output(self.dropout4(sequence_output))\n","        logits5 = self.output(self.dropout5(sequence_output))\n","\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        return logits, logits1, logits2, logits3, logits4, logits5"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"v9nTvwsIdOUw","executionInfo":{"status":"ok","timestamp":1647327714847,"user_tz":-330,"elapsed":62,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def criterion (outputs, targets, attention_mask):\n","    loss_fct = nn.CrossEntropyLoss()\n","\n","    active_loss = attention_mask.view(-1) == 1\n","    active_logits = outputs.view(-1, Config.num_labels)\n","    true_labels = targets.view(-1)\n","    outputs = active_logits.argmax(dim=-1)\n","    idxs = np.where(active_loss.cpu().numpy() == 1)[0]\n","    active_logits = active_logits[idxs]\n","    true_labels = true_labels[idxs].to(torch.long)\n","\n","    loss = loss_fct(active_logits, true_labels)\n","    return loss"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"0cUmpZIInaEr","executionInfo":{"status":"ok","timestamp":1647327714847,"user_tz":-330,"elapsed":61,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def fetch_optimizer(model, learning_rate = Config.lr):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\"]\n","    optimizer_parameters = [\n","        {\n","            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.01,\n","        },\n","        {\n","            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","    opt = AdamW(optimizer_parameters, lr=learning_rate)\n","    return opt\n","\n","def fetch_scheduler(optimizer, num_train_steps):\n","    sch = get_cosine_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=int(0.1 *  num_train_steps),\n","        num_training_steps= num_train_steps,\n","        num_cycles=1,\n","        last_epoch=-1,\n","    )\n","    return sch"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"cqvGUZV4zdGx","executionInfo":{"status":"ok","timestamp":1647327714848,"user_tz":-330,"elapsed":61,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def monitor_metrics(outputs, targets, attention_mask):\n","    active_loss = (attention_mask.view(-1) == 1).cpu().numpy()\n","    active_logits = outputs.view(-1, Config.num_labels)\n","    true_labels = targets.view(-1).cpu().numpy()\n","    outputs = active_logits.argmax(dim=-1).cpu().numpy()\n","    idxs = np.where(active_loss == 1)[0]\n","    f1_score = metrics.f1_score(true_labels[idxs], outputs[idxs], average=\"macro\")\n","    return f1_score"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"jAlUT12Wncel","executionInfo":{"status":"ok","timestamp":1647327714848,"user_tz":-330,"elapsed":61,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def calc_overlap(row):\n","    \"\"\"\n","    Calculates the overlap between prediction and\n","    ground truth and overlap percentages used for determining\n","    true positives.\n","    \"\"\"\n","    set_pred = set(row.predictionstring_pred.split(' '))\n","    set_gt = set(row.predictionstring_gt.split(' '))\n","    # Length of each and intersection\n","    len_gt = len(set_gt)\n","    len_pred = len(set_pred)\n","    inter = len(set_gt.intersection(set_pred))\n","    overlap_1 = inter / len_gt\n","    overlap_2 = inter/ len_pred\n","    return [overlap_1, overlap_2]\n","\n","\n","def score_feedback_comp(pred_df, gt_df):\n","    \"\"\"\n","    A function that scores for the kaggle\n","        Student Writing Competition\n","        \n","    Uses the steps in the evaluation page here:\n","        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n","    \"\"\"\n","    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n","        .reset_index(drop=True).copy()\n","    pred_df = pred_df[['id','class','predictionstring']] \\\n","        .reset_index(drop=True).copy()\n","    pred_df['pred_id'] = pred_df.index\n","    gt_df['gt_id'] = gt_df.index\n","    # Step 1. all ground truths and predictions for a given class are compared.\n","    joined = pred_df.merge(gt_df,\n","                           left_on=['id','class'],\n","                           right_on=['id','discourse_type'],\n","                           how='outer',\n","                           suffixes=('_pred','_gt')\n","                          )\n","    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n","    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n","\n","    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n","\n","    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n","    # and the overlap between the prediction and the ground truth >= 0.5,\n","    # the prediction is a match and considered a true positive.\n","    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n","    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n","    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n","\n","\n","    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n","    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n","    tp_pred_ids = joined.query('potential_TP') \\\n","        .sort_values('max_overlap', ascending=False) \\\n","        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n","\n","    # 3. Any unmatched ground truths are false negatives\n","    # and any unmatched predictions are false positives.\n","    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n","\n","    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n","    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n","\n","    # Get numbers of each type\n","    TP = len(tp_pred_ids)\n","    FP = len(fp_pred_ids)\n","    FN = len(unmatched_gt_ids)\n","    #calc microf1\n","    my_f1_score = TP / (TP + 0.5*(FP+FN))\n","    return my_f1_score"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"7i1T4JTl0ZPW","executionInfo":{"status":"ok","timestamp":1647327714849,"user_tz":-330,"elapsed":61,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def get_predictions(all_labels, all_scores, df):    \n","    proba_thresh = {\n","        \"Lead\": 0.7,\n","        \"Position\": 0.55,\n","        \"Evidence\": 0.65,\n","        \"Claim\": 0.55,\n","        \"Concluding Statement\": 0.7,\n","        \"Counterclaim\": 0.5,\n","        \"Rebuttal\": 0.55,\n","    }\n","    final_preds = []\n","    \n","    for i in range(len(df)):\n","        idx = df.id.values[i]\n","        pred = all_labels[i]\n","        score = all_scores[i]\n","        preds = []\n","        j = 0\n","        \n","        while j < len(pred):\n","            cls = pred[j]\n","            if cls == 'O': \n","                pass\n","            else: \n","                cls = cls.replace('B','I')\n","            end = j + 1\n","            while end < len(pred) and pred[end] == cls:\n","                end += 1\n","            # print(end - j)\n","            if cls != 'O' and cls != '' and end - j > 7:\n","                if np.mean(score[j:end]) > proba_thresh[cls.replace('I-','')]:\n","                    final_preds.append((idx, cls.replace('I-',''), \n","                                        ' '.join(map(str, list(range(j, end))))))\n","            j = end\n","    df_pred = pd.DataFrame(final_preds)\n","    df_pred.columns = ['id','class','predictionstring']\n","    return df_pred\n","\n","def threshold(df):\n","\n","    min_thresh = {\n","        \"Lead\": 9,\n","        \"Position\": 5,\n","        \"Evidence\": 14,\n","        \"Claim\": 3,\n","        \"Concluding Statement\": 11,\n","        \"Counterclaim\": 6,\n","        \"Rebuttal\": 4,\n","    }\n","\n","    df = df.copy()\n","    for key, value in min_thresh.items():\n","        index = df.loc[df[\"class\"] == key].query(f\"len<{value}\").index\n","        df.drop(index, inplace=True)\n","    return df\n","\n","def compute_val_f1(oof, df_valid):\n","    oof[\"len\"] = oof.predictionstring.apply(lambda x: len(x.split()))\n","    oof = threshold(oof)\n","    # Compute F1-score\n","    f1s = []\n","    classes = oof['class'].unique()\n","    \n","    f1s_log = {}\n","    for c in classes:\n","        pred_df = oof.loc[oof['class']==c].copy()\n","        gt_df = df_valid.loc[df_valid['discourse_type']==c].copy()\n","        f1 = score_feedback_comp(pred_df, gt_df)\n","        f1s.append(f1)\n","        f1s_log[f'F1 {c}'] = f1\n","    \n","    f1s_log['Overall F1'] = np.mean(f1s)\n","    return f1s_log"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"sCGYTxULvdNf","executionInfo":{"status":"ok","timestamp":1647327714849,"user_tz":-330,"elapsed":61,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["class Trainer:\n","    def __init__(self, config, dataloaders, valid_df, valid_df_, optimizer, model, loss_fns, scheduler, device=Config.device, apex=Config.apex):\n","        self.train_loader, self.valid_loader = dataloaders\n","        self.train_loss_fn = loss_fns\n","        self.valid_df = valid_df\n","        self.valid_df_ = valid_df_\n","        self.scheduler = scheduler\n","        self.optimizer = optimizer\n","        self.model = model\n","        self.device = device\n","        self.apex = apex\n","        self.Config = config\n","    \n","    def train_one_epoch(self):\n","        scaler = GradScaler()\n","\n","        self.model.train()\n","        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n","        dataset_size = 0\n","        running_loss = 0.0\n","        running_f1 = 0.0\n","\n","        for step, data in train_pbar:        \n","            input_ids = data[\"input_ids\"].to(self.device)\n","            input_mask = data[\"attention_mask\"].to(self.device)\n","            targets = data[\"labels\"].to(self.device)\n","\n","            batch_size = input_ids.shape[0]\n","\n","            with(autocast(enabled = True)):\n","                logits, logits1, logits2, logits3, logits4, logits5 = self.model(input_ids,\n","                                                                                input_mask)\n","                \n","                loss1 = self.train_loss_fn(logits1, targets, input_mask)\n","                loss2 = self.train_loss_fn(logits2, targets, input_mask)\n","                loss3 = self.train_loss_fn(logits3, targets, input_mask)\n","                loss4 = self.train_loss_fn(logits4, targets, input_mask)\n","                loss5 = self.train_loss_fn(logits5, targets, input_mask)\n","                loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5.0\n","                loss /= self.Config.n_accum\n","\n","            scaler.scale(loss).backward()\n","\n","            if (step + 1) % self.Config.n_accum == 0:\n","                    scaler.step(self.optimizer)\n","                    scaler.update()\n","                    self.optimizer.zero_grad()\n","                    self.scheduler.step()\n","\n","            f1_1 = monitor_metrics(logits1, targets, input_mask)\n","            f1_2 = monitor_metrics(logits2, targets, input_mask)\n","            f1_3 = monitor_metrics(logits3, targets, input_mask)\n","            f1_4 = monitor_metrics(logits4, targets, input_mask)\n","            f1_5 = monitor_metrics(logits5, targets, input_mask)\n","            f1 = (f1_1 + f1_2 + f1_3 + f1_4 + f1_5) / 5.0\n","\n","            running_loss += (loss.item() * batch_size)  \n","            running_f1 += (f1 * batch_size)  \n","            dataset_size += batch_size\n","            epoch_loss = running_loss / dataset_size\n","            epoch_f1 = running_f1 / dataset_size\n","\n","            train_pbar.set_postfix(Train_Loss = epoch_loss, Train_F1 = epoch_f1, LR = self.optimizer.param_groups[0]['lr'])\n","\n","        return epoch_loss, epoch_f1\n","\n","    @torch.no_grad()\n","    def valid_one_epoch(self):\n","\n","        self.model.eval()\n","        valid_pbar = tqdm(enumerate(self.valid_loader), total=len(self.valid_loader))\n","        dataset_size = 0\n","        ensemble_preds = np.zeros((len(self.valid_loader.dataset), self.Config.max_len, len(labels_to_ids)), dtype=np.float32)\n","        wids = np.full((len(self.valid_loader.dataset), self.Config.max_len), -100)\n","        running_loss = 0.0\n","        final_prediction = []\n","        final_scores = []\n","        predictions = defaultdict(list)\n","        prediction_scores = defaultdict(list)\n","        seen_words_idx = defaultdict(list)\n","\n","        for step , data in valid_pbar:\n","            wids[step*self.Config.valid_batch_size:(step+1)*self.Config.valid_batch_size] = data['wids'].numpy()\n","\n","            input_ids = data[\"input_ids\"].to(self.device)\n","            input_mask = data[\"attention_mask\"].to(self.device)\n","\n","            batch_size = input_ids.shape[0]\n","            logits, logits1, logits2, logits3, logits4, logits5 = self.model(input_ids,\n","                                                                            input_mask)\n","            \n","            val_preds = logits.cpu().tolist()\n","            all_preds = torch.nn.functional.softmax(logits, dim=2).cpu().detach().numpy() \n","            ensemble_preds[step*self.Config.valid_batch_size:(step+1)*self.Config.valid_batch_size] += all_preds\n","        \n","        predictions = []\n","        prediction_scores = []\n","        # INTERATE THROUGH EACH TEXT AND GET PRED\n","        for text_i in range(ensemble_preds.shape[0]):\n","            token_preds = ensemble_preds[text_i]\n","            token_prediction = np.argmax(token_preds, axis = -1)\n","            token_score = np.max(token_preds, axis = -1)\n","\n","            prediction = []\n","            prediction_score = []\n","            previous_word_idx = -1\n","            prob_buffer = []\n","            word_ids = wids[text_i][wids[text_i] != -100]\n","            for idx,word_idx in enumerate(word_ids):                            \n","                if word_idx == -1:\n","                    pass\n","                elif word_idx != previous_word_idx:              \n","                    prediction.append(ids_to_labels[token_prediction[idx]])\n","                    prediction_score.append(token_score[idx])\n","                    previous_word_idx = word_idx\n","            predictions.append(prediction)\n","            prediction_scores.append(prediction_score)\n","                    \n","        \n","        df_pred = get_predictions(predictions, prediction_scores, self.valid_df_)\n","        f1s_log = compute_val_f1(df_pred, self.valid_df)\n","\n","        return f1s_log\n","            \n","\n","    def fit(self, fold: str, epochs: int = 10, output_dir: str = \"/content/models/\", custom_name: str = 'model.pth'):\n","        \"\"\"\n","        Low-effort alternative for doing the complete training and validation process\n","        \"\"\"\n","        best_score = int(-1e+7)\n","        for epx in range(epochs):\n","            print(f\"{'='*20} Epoch: {epx+1} / {epochs} {'='*20}\")\n","\n","            train_loss, train_f1 = self.train_one_epoch()\n","            print(f\"Training loss: {train_loss:.4f} Training f1: {train_f1:.4f}\")\n","\n","            valid_score = self.valid_one_epoch()\n","\n","            print(valid_score)\n","            \n","            valid_score = valid_score['Overall F1']\n","            print(f'Validation Score: {valid_score:.4f}')\n","\n","            custom_name = f\"model_{fold}\"\n","            if valid_score > best_score:\n","                best_score = valid_score\n","                self.save_model(output_dir, custom_name)\n","                print(f\"Saved model with val_score: {best_score:.4f}\")\n","            \n","\n","    def save_model(self, path, name, verbose=False):\n","        \"\"\"\n","        Saves the model at the provided destination\n","        \"\"\"\n","        try:\n","            if not os.path.exists(path):\n","                os.makedirs(path)\n","        except:\n","            print(\"Errors encountered while making the output directory\")\n","\n","        torch.save(self.model.state_dict(), os.path.join(path, name))\n","        if verbose:\n","            print(f\"Model Saved at: {os.path.join(path, name)}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fUysspwt0bFX","colab":{"base_uri":"https://localhost:8080/","height":974,"referenced_widgets":["c926ee93d7d944a4ba64833c15d6f368","63bec23c21e74058a6fbe7e5ef529b83","cdca17818c2f434fa127ea0b3535d68c","c3240a2a53ae461d9373312f793282fe","7a621c58ba55465fafa134e41c5899df","e75e75367921464bbd3457976d7b9a4b","203190703e21451fba7a45acf18ff302","1cac897c31024856bd68d94c27801908","d31a55be8e914d7193fd6bdea41e31bb","3a205f8922fd43cc977a358ae98d8cb9","0964ead61a7044d6b124841a44ff02e8","45e94dfc347b4934b513b4196736cf16","f3e531941dca4f4cb4ed5c0b405e50e6","9e02eb76ec6047ee9148cf3c47904e93","329e3e1145f94427a966a74a7f09dc72","ade3dd7f654b4cfdaa504c9ab5c13c72","4f951a2c29c04a51afe485fa5367c475","9ab2f7fe7ee34442bd52f236abf64037","177ded2000224996a8acd384ddad6c7d","dd0213df3e0347f3b8e257582c773e1d","a0604d68a2d945aa86b41534c2f23ff8","44456f183052488f8b9b8e5d787361f4","2dba310added4aac8000aef0ff0ba259","61bce060b282413eb3da1451b7fad577","8143d54ac44b4ef0b0c465944fc39b65","3cff742c1d6e424a9c45c346ae55cfd9","7408dcaeff8b4ec482a1cf4f5a4c0ec4","ecab3a531e0242f380c2d37835f3fca4","6108695705414882a49a1f6bc0341237","348ecb2b2bfc4ea9969a00acd5874307","e11fb5da29954eb69ecfca614f37d0e5","b064889e54fb46158eb3aeefd470a0b7","0e15edb1b8964c8c9e4e996af6653867","843c072818054aa19c2aed73bc2495cd","c22c15ae3c314987ac6ecefae4ab7aa7","097512c2250a4eb693fb9000d3bd1413","3b905dd64cc64279a5e966486a98db84","070f2a18a4644e1089e7bb1e007a53a5","14234fd701f149f9ab69c619cd25bb3b","78ebf1ef8ce94634a7c3dbcd31669a8b","06b7fc2f4d5a47049b393e56b51d50bc","3147649d55f44c77b7d5f919b82269b5","abcd29836d4f4850bb3c76157ff74ddc","7cbd95660a0746d0aadd66313cbfb28f","7352b053882643308d9049187efa09b1","b18addac74314873b5002d67f17d4fc8","9faf3b71b09041b0945bddaddb704046","0aca0f13b34643b98f6855fc56b69303","afabbd5671474d569eda13dd474be58e","f4197dc5d59b4d1f944f4e193d44719a","142b1f98aa9f4bc4bf6243f54beceed7","c04473b081664b78bc7e9ea14510fc82","cfaa4c5b92ec4526b0faed4a90bfcd72","4d05c776f91c48d9a1c18e8c7e3a5d31","742f2fc90f634db9a1b6cdb617290647"]},"executionInfo":{"status":"error","timestamp":1647338888503,"user_tz":-330,"elapsed":11173009,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}},"outputId":"7c75af76-0ef4-43e1-e98e-0aad7a2c6e1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["12477 3117\n","12474 3120\n","12475 3119\n","12475 3119\n","12475 3119\n","0    28997\n","2    28968\n","3    28904\n","1    28737\n","4    28687\n","Name: kfold, dtype: int64\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15594 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c926ee93d7d944a4ba64833c15d6f368"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training Fold 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["==================== Epoch: 1 / 6 ====================\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6239 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e94dfc347b4934b513b4196736cf16"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training loss: 0.7521 Training f1: 0.4684\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1559 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dba310added4aac8000aef0ff0ba259"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'F1 Lead': 0.8088597210828548, 'F1 Position': 0.6236248872858431, 'F1 Claim': 0.5304490092710417, 'F1 Evidence': 0.7322437207066458, 'F1 Concluding Statement': 0.8334255672385169, 'F1 Counterclaim': 0.4767390341160833, 'F1 Rebuttal': 0.3582925122463261, 'Overall F1': 0.6233763502781874}\n","Validation Score: 0.6234\n","Saved model with val_score: 0.6234\n","==================== Epoch: 2 / 6 ====================\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/6239 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"843c072818054aa19c2aed73bc2495cd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training loss: 1.2164 Training f1: 0.1780\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1559 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7352b053882643308d9049187efa09b1"}},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-b08c22daec46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         trainer.fit(fold,\n\u001b[0;32m---> 54\u001b[0;31m                     Config.epochs)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-114d7e0eb955>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, fold, epochs, output_dir, custom_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss: {train_loss:.4f} Training f1: {train_f1:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mvalid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-114d7e0eb955>\u001b[0m in \u001b[0;36mvalid_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_df_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mf1s_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_val_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-085273ae440c>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(all_labels, all_scores, df)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdf_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predictionstring'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5499\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5501\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             raise ValueError(\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 3 elements"]}],"source":["if __name__ == \"__main__\":\n","    df = pd.read_csv(os.path.join(Config.input, \"corrected_train.csv\"))\n","    if Config.debug:\n","        df = df[:100]\n","    df = create_folds(df)\n","    df_text = get_texts(\"/content/data/train/\")\n","    df_text = get_labels(df_text, df)\n","\n","    os.makedirs(\"models\", exist_ok = True)\n","    for fold in range(0,2):\n","\n","        print(f\"Training Fold {fold}\")\n","        df_text = df_text[['id','text', 'entities']]\n","        train_df = df[df[\"kfold\"] != fold].reset_index(drop=True)\n","        valid_df = df[df[\"kfold\"] == fold].reset_index(drop=True)\n","        train_idx = train_df[\"id\"].unique()\n","        valid_idx = valid_df[\"id\"].unique()\n","        train_df_ = df_text.loc[df_text.id.isin(train_idx)].reset_index(drop=True)\n","        valid_df_ = df_text.loc[df_text.id.isin(valid_idx)].reset_index(drop=True)\n","        tokenizer = AutoTokenizer.from_pretrained(Config.model)\n","\n","        train_dataset = feedbackDataset(train_df_, tokenizer, Config.max_len, False)\n","        valid_dataset = feedbackDataset(valid_df_, tokenizer, Config.max_len, True)\n","\n","        num_train_steps = int(len(train_dataset) / Config.batch_size / Config.accumulation_steps * Config.epochs)\n","        model = FeedbackModel(Config.model,\n","                               Config.num_labels)        \n","        model.to(Config.device)\n","        optimizer = fetch_optimizer(model)\n","        scheduler = fetch_scheduler(optimizer, num_train_steps)\n","        \n","        train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                                batch_size = Config.batch_size,\n","                                                pin_memory = True,\n","                                                num_workers = Config.num_workers,  \n","                                                shuffle = True)\n","        \n","        valid_loader = torch.utils.data.DataLoader(valid_dataset,\n","                                                batch_size = Config.valid_batch_size,\n","                                                pin_memory = True,\n","                                                num_workers = Config.num_workers,  \n","                                                shuffle = False)\n","        \n","        trainer = Trainer(config = Config,\n","                        dataloaders =(train_loader, valid_loader) ,\n","                        valid_df = valid_df,\n","                        valid_df_ = valid_df_,\n","                        optimizer = optimizer,\n","                        model = model,\n","                        loss_fns = criterion,\n","                        scheduler = scheduler)\n","        \n","        trainer.fit(fold,\n","                    Config.epochs)\n","        \n","        del model\n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R129jKkYfpz_","executionInfo":{"status":"aborted","timestamp":1647311386650,"user_tz":-330,"elapsed":10,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["save_file = f\"drive/MyDrive/{Config.savename}.zip\" \n","! zip -r $save_file models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzVs36XcPc5x","executionInfo":{"status":"aborted","timestamp":1647311386652,"user_tz":-330,"elapsed":12,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["weights = [\n","        #    \"models/model_0\",\n","        #    \"models/model_1\",\n","        #    \"models/model_2\",\n","           \"models/model_3\",\n","           \"models/model_4\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akMR34bsLWdt","executionInfo":{"status":"aborted","timestamp":1647299767385,"user_tz":-330,"elapsed":25,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["@torch.no_grad()\n","def inference(model, data_loader):\n","    model.eval()\n","\n","    ensemble_preds = np.zeros((len(data_loader.dataset), Config.max_len, len(labels_to_ids)), dtype=np.float32)\n","    wids = np.full((len(data_loader.dataset), Config.max_len), -100)\n","\n","    for fold in range(Config.n_folds):\n","        model.load_state_dict(torch.load(weights[fold]))\n","        infer_pbar = tqdm(enumerate(data_loader), total = len(data_loader))\n","\n","        for step, data in infer_pbar:\n","            wids[step*Config.valid_batch_size:(step+1)*Config.valid_batch_size] = data['wids'].numpy()\n","\n","            input_ids = data[\"input_ids\"].to(Config.device)\n","            input_mask = data[\"attention_mask\"].to(Config.device)\n","\n","            batch_size = input_ids.shape[0]\n","            logits, logits1, logits2, logits3, logits4, logits5 = model(input_ids,\n","                                                                            input_mask)\n","            \n","            val_preds = logits.cpu().tolist()\n","            all_preds = torch.nn.functional.softmax(logits, dim=2).cpu().detach().numpy() \n","            ensemble_preds[step*Config.valid_batch_size:(step+1)*Config.valid_batch_size] += all_preds / 5\n","\n","    predictions = []\n","    prediction_scores = []\n","    # INTERATE THROUGH EACH TEXT AND GET PRED\n","    for text_i in range(ensemble_preds.shape[0]):\n","        token_preds = ensemble_preds[text_i]\n","\n","        prediction = []\n","        previous_word_idx = -1\n","        prob_buffer = []\n","        word_ids = wids[text_i][wids[text_i] != -100]\n","        for idx,word_idx in enumerate(word_ids):                            \n","            if word_idx == -1:\n","                pass\n","            elif word_idx != previous_word_idx:              \n","                prediction.append(token_preds[idx])\n","                previous_word_idx = word_idx\n","        predictions.append(prediction)\n","                \n","    \n","    return predictions\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7AGGQD5mxg_","executionInfo":{"status":"aborted","timestamp":1647299767386,"user_tz":-330,"elapsed":26,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["class SeqDataset(object):\n","    \n","    def __init__(self, features, labels, groups, wordRanges, truePos):\n","        \n","        self.features = np.array(features, dtype=np.float32)\n","        self.labels = np.array(labels)\n","        self.groups = np.array(groups, dtype=np.int16)\n","        self.wordRanges = np.array(wordRanges, dtype=np.int16)\n","        self.truePos = np.array(truePos)\n","\n","def sorted_quantile(array, q):\n","    array = np.array(array)\n","    n = len(array)\n","    index = (n - 1) * q\n","    left = np.floor(index).astype(int)\n","    fraction = index - left\n","    right = left\n","    right = right + (fraction > 0).astype(int)\n","    i, j = array[left], array[right]\n","    return i + (j - i) * fraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGEYQn5gm-X5","executionInfo":{"status":"aborted","timestamp":1647299767386,"user_tz":-330,"elapsed":26,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def seq_dataset(disc_type, valid_word_preds, valid, test_dataset, pred_indices=None):\n","    word_preds = valid_word_preds\n","    window = pred_indices if pred_indices else range(len(word_preds))\n","    X = np.empty((int(1e6),13), dtype=np.float32)\n","    X_ind = 0\n","    y = []\n","    truePos = []\n","    wordRanges = []\n","    groups = []\n","    for text_i in tqdm(window):\n","        text_preds = np.array(word_preds[text_i])\n","        num_words = len(text_preds)\n","        disc_begin, disc_inside = disc_type_to_ids[disc_type]\n","        \n","        # The probability that a word corresponds to either a 'B'-egin or 'I'-nside token for a class\n","        prob_or = lambda word_preds: (1-(1-word_preds[:,disc_begin]) * (1-word_preds[:,disc_inside]))\n","        \n","        gt_idx = set()\n","        gt_arr = np.zeros(num_words, dtype=int)\n","        text_gt = valid.loc[valid.id == test_dataset.id.values[text_i]]\n","        disc_gt = text_gt.loc[text_gt.discourse_type == disc_type]\n","        \n","        # Represent the discourse instance locations in a hash set and an integer array for speed\n","        for row_i, row in enumerate(disc_gt.iterrows()):\n","            splt = row[1]['predictionstring'].split()\n","            start, end = int(splt[0]), int(splt[-1]) + 1\n","            gt_idx.add((start, end))\n","            gt_arr[start:end] = row_i + 1\n","        gt_lens = np.bincount(gt_arr)\n","        \n","        # Iterate over every sub-sequence in the text\n","        quants = np.linspace(0,1,7)\n","        prob_begins = np.copy(text_preds[:,disc_begin])\n","        min_begin = MIN_BEGIN_PROB[disc_type]\n","        for pred_start in range(num_words):\n","            prob_begin = prob_begins[pred_start]\n","            if prob_begin > min_begin:\n","                begin_or_inside = []\n","                for pred_end in range(pred_start+1,min(num_words+1, pred_start+MAX_SEQ_LEN[disc_type]+1)):\n","                    \n","                    new_prob = prob_or(text_preds[pred_end-1:pred_end])\n","                    insert_i = bisect_left(begin_or_inside, new_prob)\n","                    begin_or_inside.insert(insert_i, new_prob[0])\n","\n","                    # Generate features for a word sub-sequence\n","\n","                    # The length and position of start/end of the sequence\n","                    features = [pred_end - pred_start, pred_start / float(num_words), pred_end / float(num_words)]\n","                    \n","                    # 7 evenly spaced quantiles of the distribution of relevant class probabilities for this sequence\n","                    features.extend(list(sorted_quantile(begin_or_inside, quants)))\n","\n","                    # The probability that words on either edge of the current sub-sequence belong to the class of interest\n","                    features.append(prob_or(text_preds[pred_start-1:pred_start])[0] if pred_start > 0 else 0)\n","                    features.append(prob_or(text_preds[pred_end:pred_end+1])[0] if pred_end < num_words else 0)\n","\n","                    # The probability that the first word corresponds to a 'B'-egin token\n","                    features.append(text_preds[pred_start,disc_begin])\n","\n","                    exact_match = (pred_start, pred_end) in gt_idx\n","\n","                    true_pos = False\n","                    for match_cand, count in Counter(gt_arr[pred_start:pred_end]).most_common(2):\n","                        if match_cand != 0 and count / float(pred_end - pred_start) >= .5 and float(count) / gt_lens[match_cand] >= .5: true_pos = True\n","              \n","\n","                    # For efficiency, use a numpy array instead of a list that doubles in size when full to conserve constant \"append\" time complexity\n","                    if X_ind >= X.shape[0]:\n","                        new_X = np.empty((X.shape[0]*2,13), dtype=np.float32)\n","                        new_X[:X.shape[0]] = X\n","                        X = new_X\n","                    X[X_ind] = features\n","                    X_ind += 1\n","                    \n","                    y.append(exact_match)\n","                    truePos.append(true_pos)\n","                    wordRanges.append((np.int16(pred_start), np.int16(pred_end)))\n","                    groups.append(np.int16(text_i))\n","\n","    return SeqDataset(X[:X_ind], y, groups, wordRanges, truePos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6YutXnIohki","executionInfo":{"status":"aborted","timestamp":1647299767387,"user_tz":-330,"elapsed":27,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["NEGATIVE_SAMPLE_RATIO = 1\n","\n","# Downsample negative samples to 1:1 for efficiency/ease. There are many samples, and performance increase was observed.\n","def resample(y):\n","    global resample_call\n","    counts = np.bincount(y)\n","    np.random.seed((resample_call+counts[0]) % 2**32)\n","    \n","    neg_sample_count = NEGATIVE_SAMPLE_RATIO*counts[1]\n","    indices = np.concatenate((\n","        np.random.choice(np.arange(len(y))[y==0], neg_sample_count, replace=False),\n","        np.arange(len(y))[y==1]\n","    ))\n","    indices.sort()\n","    resample_call += 1\n","    return indices\n","\n","resample_call = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRSk_fRhoplP","executionInfo":{"status":"aborted","timestamp":1647299767387,"user_tz":-330,"elapsed":27,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def predict_strings(disc_type, probThresh, test_groups, test_dataset, train_text_df, train_ind=None):\n","    string_preds = []\n","    validSeqDs = validSeqSets[disc_type]\n","    \n","    # Average the probability predictions of a set of classifiers\n","    get_tp_prob = lambda testDs, classifiers: np.mean([clf.predict_proba(testDs.features)[:,1] for clf in classifiers], axis=0) if testDs.features.shape[0] > 0 else np.array([])\n","    \n","    # Point to validation set values\n","    predict_df = test_dataset\n","    text_df = train_text_df\n","    groupIdx = np.isin(validSeqDs.groups, test_groups)\n","    testDs = SeqDataset(validSeqDs.features[groupIdx], validSeqDs.labels[groupIdx], validSeqDs.groups[groupIdx], validSeqDs.wordRanges[groupIdx], validSeqDs.truePos[groupIdx])\n","    \n","    # Cache the classifier predictions to speed up tuning iterations\n","    seq_key = (disc_type, tuple(test_groups), tuple(train_ind))\n","    if seq_key in seq_cache:\n","        text_to_seq = seq_cache[seq_key]\n","    else:\n","\n","        clf = xgboost.XGBClassifier(\n","            learning_rate = 0.05,\n","            n_estimators=200,\n","            max_depth=7,\n","            min_child_weight=5,\n","            gamma=0,\n","            subsample=0.7,\n","            reg_alpha=.0005,\n","            colsample_bytree=0.6,\n","            scale_pos_weight=1,\n","            use_label_encoder=False,\n","            eval_metric='logloss',\n","            tree_method='hist'\n","        )\n","        \n","        resampled = resample(validSeqDs.truePos[train_ind])\n","        clf.fit(validSeqDs.features[train_ind][resampled],validSeqDs.truePos[train_ind][resampled])\n","        clfs.append(clf)\n","        prob_tp = get_tp_prob(testDs, [clf])\n","        \n","        \n","    if seq_key not in seq_cache:\n","        text_to_seq = {}\n","        for text_idx in test_groups:\n","            # The probability of true positive and (start,end) of each sub-sequence in the curent text\n","            prob_tp_curr = prob_tp[testDs.groups == text_idx]\n","            word_ranges_curr = testDs.wordRanges[testDs.groups == text_idx]\n","            sorted_seqs = list(reversed(sorted(zip(prob_tp_curr, [tuple(wr) for wr in word_ranges_curr]))))\n","            text_to_seq[text_idx] = sorted_seqs\n","        seq_cache[seq_key] = text_to_seq\n","    \n","    for text_idx in test_groups:\n","        \n","        i = 1\n","        split_text = text_df.loc[text_df.id == predict_df.id.values[text_idx]].iloc[0].text.split()\n","        \n","        # Start and end word indices of sequence candidates kept in sorted order for efficiency\n","        starts = []\n","        ends = []\n","        \n","        # Include the sub-sequence predictions in order of predicted probability\n","        for prob, wordRange in text_to_seq[text_idx]:\n","            \n","            # Until the predicted probability is lower than the tuned threshold\n","            if prob < probThresh: break\n","                \n","            # Binary search already-placed word sequence intervals, and insert the new word sequence interval if it does not intersect an existing interval.\n","            insert = bisect_left(starts, wordRange[0])\n","            if (insert == 0 or ends[insert-1] <= wordRange[0]) and (insert == len(starts) or starts[insert] >= wordRange[1]):\n","                starts.insert(insert, wordRange[0])\n","                ends.insert(insert, wordRange[1])\n","                string_preds.append((predict_df.id.values[text_idx], disc_type, ' '.join(map(str, list(range(wordRange[0], wordRange[1]))))))\n","                i += 1     \n","    return string_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49dYjMVCoqLy","executionInfo":{"status":"aborted","timestamp":1647299767388,"user_tz":-330,"elapsed":27,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def sub_df(string_preds):\n","    return pd.DataFrame(string_preds, columns=['id','class','predictionstring'])\n","    \n","# Convert skopt's uniform distribution over the tuning threshold to a distribution that exponentially decays from 100% to 0%\n","def prob_thresh(x): \n","    return .01*(100-np.exp(100*x))\n","\n","# Convert back to the scalar supplied by skopt\n","def skopt_thresh(x): \n","    return np.log((x/.01-100.)/-1.)/100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6awELCZHotLG","executionInfo":{"status":"aborted","timestamp":1647299767388,"user_tz":-330,"elapsed":27,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def score_fmin(arr, disc_type, test_dataset, valid, train_text_df):\n","    validSeqDs = validSeqSets[disc_type]\n","    string_preds = []\n","    folds = np.array(list(GroupKFold(n_splits=NUM_FOLDS).split(validSeqDs.features, groups=validSeqDs.groups)))\n","    gt_indices = []\n","    for ind in folds[:,1]: gt_indices.extend(ind)\n","        \n","    # Texts that have no samples in our dataset for this class\n","    unsampled_texts = np.array(np.array_split(list(set(uniqueValidGroups).difference(set(np.unique(validSeqDs.groups)))), NUM_FOLDS))\n","    \n","    gt_texts = test_dataset.id.values[np.unique(validSeqDs.groups[np.array(gt_indices, dtype=int)]).astype(int)]\n","    \n","    # Generate predictions from each fold of the validation set\n","    for fold_i, (train_ind, test_ind) in enumerate(folds):\n","        string_preds.extend(predict_strings(disc_type, prob_thresh(arr[0]), np.concatenate((np.unique(validSeqDs.groups[test_ind]), unsampled_texts[fold_i])).astype(int), test_dataset, train_text_df, train_ind))\n","    boost_df = sub_df(list(string_preds))\n","    gt_df = valid.loc[np.bitwise_and(valid['discourse_type']==disc_type, valid.id.isin(gt_texts))].copy()\n","    f1 = score_feedback_comp(boost_df.copy(), gt_df)\n","    return -f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mENHdfdLowNc","executionInfo":{"status":"aborted","timestamp":1647299767389,"user_tz":-330,"elapsed":28,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["def train_seq_clfs(disc_type, test_dataset, valid, train_text_df):\n","    print(f\"Training Sequence Classifier: {disc_type}\")\n","    # The optimization bounds on the tuned probability threshold \n","    space_start = skopt_thresh(.999)\n","    space_end = skopt_thresh(0)\n","    space  = [Real(space_start,space_end)]\n","    \n","    # Minimize F1\n","    score_fmin_disc = lambda arr: score_fmin(arr, disc_type, test_dataset, valid, df_text)\n","    res_gp = gp_minimize(score_fmin_disc, space, n_calls=100, x0=[skopt_thresh(.5)])\n","    \n","    # Use the gaussian approximation of f(threshold) -> F1 to select the minima\n","    thresh_cand = np.rot90([np.linspace(0,1,1000)])\n","    cand_scores = res_gp.models[-1].predict(thresh_cand)\n","    best_thresh_raw = space_start + (space_end - space_start)*thresh_cand[np.argmin(cand_scores)][0]\n","    best_thresh = prob_thresh(best_thresh_raw)\n","    exp_score = -np.min(cand_scores)\n","    \n","    # Make predictions at the inferred function minimum\n","    pred_thresh_score = -score_fmin_disc([best_thresh_raw])\n","    \n","    # And the best iteration in the optimization run\n","    best_iter_score = -score_fmin_disc(res_gp.x)\n","    \n","    # Save the trained classifiers to disc\n","    with open( f\"clfs/{disc_type}_clf.p\", \"wb\" ) as clfFile:\n","        pickle.dump( clfs, clfFile )\n","        \n","    # Save the tuning run results to file\n","    with open( f\"results/{disc_type}_res.p\", \"wb\" ) as resFile:\n","        pickle.dump( \n","            {\n","                'pred_thresh': best_thresh,  # The location of the minimum of the gaussian function inferred by skopt\n","                'min_thresh': prob_thresh(res_gp.x[0]),  # The threshold which produces the best score\n","                'pred_score': exp_score,  # The minimum of the gaussian function inferred by skopt\n","                'min_score': best_iter_score, # The best score in the tuning run\n","                'pred_thresh_score': pred_thresh_score  # The score produced by 'pred_thresh'\n","            }, \n","            resFile \n","        )\n","    print('Done training', disc_type)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrziU5x2z0DG","executionInfo":{"status":"aborted","timestamp":1647299767389,"user_tz":-330,"elapsed":28,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["if __name__ == \"__main__\":\n","    os.makedirs(\"clfs\", exist_ok = True)\n","    os.makedirs(\"results\", exist_ok = True)\n","    df = pd.read_csv(os.path.join(Config.input, \"corrected_train.csv\"))\n","    if Config.debug:\n","        df = df[:100]\n","    df = create_folds(df)\n","\n","    NUM_FOLDS = 4\n","    MAX_SEQ_LEN = {}\n","    df['len'] = df['predictionstring'].apply(lambda x:len(x.split()))\n","    max_lens = df.groupby('discourse_type')['len'].quantile(.995)\n","    for disc_type in disc_type_to_ids:\n","        MAX_SEQ_LEN[disc_type] = int(max_lens[disc_type])\n","\n","    df_text = get_texts(\"/content/data/train/\")\n","    df_text = get_labels(df_text, df)\n","\n","    MIN_BEGIN_PROB = {\n","        'Claim': .35,\n","        'Concluding Statement': .15,\n","        'Counterclaim': .04,\n","        'Evidence': .1,\n","        'Lead': .32,\n","        'Position': .25,\n","        'Rebuttal': .01,\n","    }\n","    \n","\n","    df_text = df_text[['id','text', 'entities']]\n","    train_df = df[df[\"kfold\"] != 0]\n","    valid_df = df[df[\"kfold\"] == 0]\n","    train_idx = train_df[\"id\"].unique()\n","    valid_idx = valid_df[\"id\"].unique()\n","    train_df_ = df_text.loc[df_text.id.isin(train_idx)].reset_index(drop=True)\n","    valid_df_ = df_text.loc[df_text.id.isin(valid_idx)].reset_index(drop=True)\n","    tokenizer = AutoTokenizer.from_pretrained(Config.model)\n","\n","    train_dataset = feedbackDataset(train_df_, tokenizer, Config.max_len, False)\n","    valid_dataset = feedbackDataset(valid_df_, tokenizer, Config.max_len, True)\n","\n","    num_train_steps = int(len(train_dataset) / Config.batch_size / Config.accumulation_steps * Config.epochs)\n","    model = FeedbackModel(Config.model,\n","                            Config.num_labels)        \n","    model.to(Config.device)\n","    optimizer = fetch_optimizer(model)\n","    scheduler = fetch_scheduler(optimizer, num_train_steps)\n","    \n","    train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                            batch_size = Config.batch_size,\n","                                            pin_memory = True,\n","                                            num_workers = Config.num_workers,  \n","                                            shuffle = True)\n","    \n","    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n","                                            batch_size = Config.valid_batch_size,\n","                                            pin_memory = True,\n","                                            num_workers = Config.num_workers,  \n","                                            shuffle = False)\n","    \n","    if not os.path.exists(\"valid_preds.p\"):\n","        predictions = inference(model, valid_loader)\n","        with open(f\"valid_preds.p\", \"wb\" ) as validFile:\n","            pickle.dump( predictions, validFile )\n","    else:\n","        with open(\"valid_preds.p\", \"rb\" ) as validFile:\n","            predictions = pickle.load( validFile ) \n","\n","    uniqueValidGroups = range(len(predictions))\n","\n","    manager = Manager()\n","    validSeqSets = manager.dict()\n","\n","    def sequenceDataset(disc_type):\n","        print(disc_type)\n","        validSeqSets[disc_type] = seq_dataset(disc_type, predictions, valid_df, valid_df_)\n","\n","    if not os.path.exists(\"valid_seqds.p\"):\n","        print('Making validation sequence datasets...')        \n","        Parallel(n_jobs=-1, backend='multiprocessing')(\n","                delayed(sequenceDataset)(disc_type) \n","                for disc_type in disc_type_to_ids\n","            )\n","        with open(f\"valid_seqds.p\", \"wb\" ) as validFile:\n","            pickle.dump( dict(validSeqSets), validFile )\n","        print('Done.')\n","    else:\n","        with open(f\"valid_seqds.p\", \"rb\" ) as validFile:\n","            validSeqSets = pickle.load( validFile )\n","            \n","        \n","\n","    seq_cache = {} \n","    clfs = []\n","    print('Training sequence classifiers... (This takes a long time.)')\n","    Parallel(n_jobs=-1, backend='multiprocessing')(\n","            delayed(train_seq_clfs)(disc_type, valid_df_, valid_df, train_df_) \n","        for disc_type in disc_type_to_ids\n","    )\n","    print('Done training all sequence classifiers.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBEIwBnV6bKh","executionInfo":{"status":"aborted","timestamp":1647299767390,"user_tz":-330,"elapsed":29,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["thresholds = {}\n","for disc_type in disc_type_to_ids:\n","    with open( f\"results/{disc_type}_res.p\", \"rb\" ) as res_file:\n","        train_result = pickle.load( res_file )  \n","    thresholds[disc_type] = train_result['pred_thresh']\n","    print(disc_type, train_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wze-zsRB3H--","executionInfo":{"status":"aborted","timestamp":1647299767391,"user_tz":-330,"elapsed":30,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["save_name = f\"/content/drive/MyDrive/FB_{Config.savename}-clf.zip\"\n","!zip -r $save_name clfs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pkXdvak3dDi","executionInfo":{"status":"aborted","timestamp":1647299767391,"user_tz":-330,"elapsed":30,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":["save_name = f\"/content/drive/MyDrive/FB_{Config.savename}-result.zip\"\n","!zip -r $save_name results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJegDQgQ-GSz","executionInfo":{"status":"aborted","timestamp":1647299767392,"user_tz":-330,"elapsed":31,"user":{"displayName":"Aishik Rakshit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoE8DoXrkkE1neQvac-1XEvBsREdaljei0HYrDfw=s64","userId":"15122983906308089605"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"FB Pytorch Train V2- 1","provenance":[{"file_id":"1llVC5skg-4JHTs3mk7O2PdDqkx2kBtcQ","timestamp":1646846523539},{"file_id":"1CJvVkxMocb8YzqgdEsTrR2f827Ceh9ye","timestamp":1646836395242}],"background_execution":"on","mount_file_id":"1kVr9CQjMMp9fWLr6iS-101vhi9MN1AwI","authorship_tag":"ABX9TyPoPjoCLnY3rLEORnbDmRlD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c926ee93d7d944a4ba64833c15d6f368":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63bec23c21e74058a6fbe7e5ef529b83","IPY_MODEL_cdca17818c2f434fa127ea0b3535d68c","IPY_MODEL_c3240a2a53ae461d9373312f793282fe"],"layout":"IPY_MODEL_7a621c58ba55465fafa134e41c5899df"}},"63bec23c21e74058a6fbe7e5ef529b83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e75e75367921464bbd3457976d7b9a4b","placeholder":"​","style":"IPY_MODEL_203190703e21451fba7a45acf18ff302","value":"100%"}},"cdca17818c2f434fa127ea0b3535d68c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cac897c31024856bd68d94c27801908","max":15594,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d31a55be8e914d7193fd6bdea41e31bb","value":15594}},"c3240a2a53ae461d9373312f793282fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a205f8922fd43cc977a358ae98d8cb9","placeholder":"​","style":"IPY_MODEL_0964ead61a7044d6b124841a44ff02e8","value":" 15594/15594 [02:26&lt;00:00, 107.80it/s]"}},"7a621c58ba55465fafa134e41c5899df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e75e75367921464bbd3457976d7b9a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"203190703e21451fba7a45acf18ff302":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cac897c31024856bd68d94c27801908":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d31a55be8e914d7193fd6bdea41e31bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a205f8922fd43cc977a358ae98d8cb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0964ead61a7044d6b124841a44ff02e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45e94dfc347b4934b513b4196736cf16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3e531941dca4f4cb4ed5c0b405e50e6","IPY_MODEL_9e02eb76ec6047ee9148cf3c47904e93","IPY_MODEL_329e3e1145f94427a966a74a7f09dc72"],"layout":"IPY_MODEL_ade3dd7f654b4cfdaa504c9ab5c13c72"}},"f3e531941dca4f4cb4ed5c0b405e50e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f951a2c29c04a51afe485fa5367c475","placeholder":"​","style":"IPY_MODEL_9ab2f7fe7ee34442bd52f236abf64037","value":"100%"}},"9e02eb76ec6047ee9148cf3c47904e93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_177ded2000224996a8acd384ddad6c7d","max":6239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd0213df3e0347f3b8e257582c773e1d","value":6239}},"329e3e1145f94427a966a74a7f09dc72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0604d68a2d945aa86b41534c2f23ff8","placeholder":"​","style":"IPY_MODEL_44456f183052488f8b9b8e5d787361f4","value":" 6239/6239 [1:28:58&lt;00:00,  1.30it/s, LR=2.37e-5, Train_F1=0.468, Train_Loss=0.752]"}},"ade3dd7f654b4cfdaa504c9ab5c13c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f951a2c29c04a51afe485fa5367c475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ab2f7fe7ee34442bd52f236abf64037":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"177ded2000224996a8acd384ddad6c7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd0213df3e0347f3b8e257582c773e1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0604d68a2d945aa86b41534c2f23ff8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44456f183052488f8b9b8e5d787361f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dba310added4aac8000aef0ff0ba259":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61bce060b282413eb3da1451b7fad577","IPY_MODEL_8143d54ac44b4ef0b0c465944fc39b65","IPY_MODEL_3cff742c1d6e424a9c45c346ae55cfd9"],"layout":"IPY_MODEL_7408dcaeff8b4ec482a1cf4f5a4c0ec4"}},"61bce060b282413eb3da1451b7fad577":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecab3a531e0242f380c2d37835f3fca4","placeholder":"​","style":"IPY_MODEL_6108695705414882a49a1f6bc0341237","value":"100%"}},"8143d54ac44b4ef0b0c465944fc39b65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_348ecb2b2bfc4ea9969a00acd5874307","max":1559,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e11fb5da29954eb69ecfca614f37d0e5","value":1559}},"3cff742c1d6e424a9c45c346ae55cfd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b064889e54fb46158eb3aeefd470a0b7","placeholder":"​","style":"IPY_MODEL_0e15edb1b8964c8c9e4e996af6653867","value":" 1559/1559 [05:09&lt;00:00,  5.86it/s]"}},"7408dcaeff8b4ec482a1cf4f5a4c0ec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecab3a531e0242f380c2d37835f3fca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6108695705414882a49a1f6bc0341237":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"348ecb2b2bfc4ea9969a00acd5874307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e11fb5da29954eb69ecfca614f37d0e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b064889e54fb46158eb3aeefd470a0b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e15edb1b8964c8c9e4e996af6653867":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"843c072818054aa19c2aed73bc2495cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c22c15ae3c314987ac6ecefae4ab7aa7","IPY_MODEL_097512c2250a4eb693fb9000d3bd1413","IPY_MODEL_3b905dd64cc64279a5e966486a98db84"],"layout":"IPY_MODEL_070f2a18a4644e1089e7bb1e007a53a5"}},"c22c15ae3c314987ac6ecefae4ab7aa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14234fd701f149f9ab69c619cd25bb3b","placeholder":"​","style":"IPY_MODEL_78ebf1ef8ce94634a7c3dbcd31669a8b","value":"100%"}},"097512c2250a4eb693fb9000d3bd1413":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06b7fc2f4d5a47049b393e56b51d50bc","max":6239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3147649d55f44c77b7d5f919b82269b5","value":6239}},"3b905dd64cc64279a5e966486a98db84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abcd29836d4f4850bb3c76157ff74ddc","placeholder":"​","style":"IPY_MODEL_7cbd95660a0746d0aadd66313cbfb28f","value":" 6239/6239 [1:23:36&lt;00:00,  1.42it/s, LR=1.18e-5, Train_F1=0.178, Train_Loss=1.22]"}},"070f2a18a4644e1089e7bb1e007a53a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14234fd701f149f9ab69c619cd25bb3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78ebf1ef8ce94634a7c3dbcd31669a8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06b7fc2f4d5a47049b393e56b51d50bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3147649d55f44c77b7d5f919b82269b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abcd29836d4f4850bb3c76157ff74ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cbd95660a0746d0aadd66313cbfb28f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7352b053882643308d9049187efa09b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b18addac74314873b5002d67f17d4fc8","IPY_MODEL_9faf3b71b09041b0945bddaddb704046","IPY_MODEL_0aca0f13b34643b98f6855fc56b69303"],"layout":"IPY_MODEL_afabbd5671474d569eda13dd474be58e"}},"b18addac74314873b5002d67f17d4fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4197dc5d59b4d1f944f4e193d44719a","placeholder":"​","style":"IPY_MODEL_142b1f98aa9f4bc4bf6243f54beceed7","value":"100%"}},"9faf3b71b09041b0945bddaddb704046":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c04473b081664b78bc7e9ea14510fc82","max":1559,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfaa4c5b92ec4526b0faed4a90bfcd72","value":1559}},"0aca0f13b34643b98f6855fc56b69303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d05c776f91c48d9a1c18e8c7e3a5d31","placeholder":"​","style":"IPY_MODEL_742f2fc90f634db9a1b6cdb617290647","value":" 1559/1559 [05:09&lt;00:00,  5.85it/s]"}},"afabbd5671474d569eda13dd474be58e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4197dc5d59b4d1f944f4e193d44719a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142b1f98aa9f4bc4bf6243f54beceed7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c04473b081664b78bc7e9ea14510fc82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfaa4c5b92ec4526b0faed4a90bfcd72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d05c776f91c48d9a1c18e8c7e3a5d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"742f2fc90f634db9a1b6cdb617290647":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}